# ============================================================
#  Clasificaci贸n de calidad del sue帽o usando rboles y Bosques Aleatorios
# Este c贸digo est谩 preparado para ejecutarse en un Jupyter Notebook.
# Incluye comentarios explicativos para comprender cada paso del proceso.
# ============================================================

# --- Importaci贸n de librer铆as necesarias ---
import pandas as pd  # Para manejar datasets en formato DataFrame
from sklearn.model_selection import train_test_split  # Para dividir los datos en entrenamiento y prueba
from sklearn.tree import DecisionTreeClassifier  # Clasificador basado en 谩rboles de decisi贸n
from sklearn.ensemble import RandomForestClassifier  # Clasificador basado en bosques aleatorios (bagging)
from sklearn.metrics import confusion_matrix, classification_report  # M茅tricas de evaluaci贸n
import seaborn as sns  # Librer铆a para visualizaci贸n
import matplotlib.pyplot as plt  # Librer铆a para gr谩ficos

# --- Cargar el dataset ---
# Asegurate de tener el archivo 'screentime.csv' en el mismo directorio del notebook.
df = pd.read_csv("screentime.csv")

# --- Preprocesamiento de datos ---
# Eliminamos columnas no num茅ricas o irrelevantes para el modelo.
# Estas columnas pueden no aportar informaci贸n 煤til al entrenamiento.
df = df.drop(columns=['user_id', 'gender', 'occupation', 'work_mode'])

# --- Definici贸n de variables ---
# 'X' contiene las caracter铆sticas predictoras.
# 'y' contiene la variable objetivo: la calidad del sue帽o en una escala del 1 al 5.
X = df.drop(columns=['sleep_quality_1_5'])
y = df['sleep_quality_1_5']

# --- Divisi贸n del dataset ---
# Separaci贸n en conjunto de entrenamiento (70%) y prueba (30%).
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# --- Entrenamiento del modelo de rbol de Decisi贸n ---
# Se limita la profundidad m谩xima a 5 para evitar sobreajuste.
dt = DecisionTreeClassifier(max_depth=5, random_state=42)
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)

# --- Entrenamiento del modelo de Random Forest ---
# Random Forest combina m煤ltiples 谩rboles entrenados sobre subconjuntos del dataset (bagging).
rf = RandomForestClassifier(n_estimators=100, max_samples=0.8, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

# --- Evaluaci贸n mediante matrices de confusi贸n ---
# Se generan dos gr谩ficos lado a lado para comparar los modelos.
fig, axes = plt.subplots(1, 2, figsize=(10, 4))

# Matriz de confusi贸n para rbol de Decisi贸n
sns.heatmap(confusion_matrix(y_test, y_pred_dt), annot=True, fmt='d', cmap='Blues', ax=axes[0])
axes[0].set_title('Decision Tree')
axes[0].set_xlabel('Predicho')
axes[0].set_ylabel('Real')

# Matriz de confusi贸n para Random Forest
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Greens', ax=axes[1])
axes[1].set_title('Random Forest')
axes[1].set_xlabel('Predicho')
axes[1].set_ylabel('Real')

# Ajuste del dise帽o de los gr谩ficos
plt.tight_layout()
plt.show()

# --- Reportes de clasificaci贸n ---
# Muestra m茅tricas como precisi贸n, recall y F1-score para ambos modelos.
print("=== Decision Tree ===")
print(classification_report(y_test, y_pred_dt))

print("=== Random Forest ===")
print(classification_report(y_test, y_pred_rf))