# ===============================================================
# üå∏ Clasificaci√≥n del dataset Iris con MLP, SVM y √Årbol de Decisi√≥n
# Este notebook entrena y compara tres modelos distintos de clasificaci√≥n
# sobre el cl√°sico dataset Iris. Cada secci√≥n est√° comentada para mayor claridad.
# ===============================================================

# --- Importaci√≥n de librer√≠as necesarias ---
from sklearn.datasets import load_iris                  # Dataset Iris
from sklearn.model_selection import train_test_split    # Divisi√≥n train/test
from sklearn.preprocessing import StandardScaler        # Normalizaci√≥n de datos
from sklearn.neural_network import MLPClassifier        # Red neuronal multicapa (MLP)
from sklearn.svm import SVC                             # M√°quina de soporte vectorial
from sklearn.tree import DecisionTreeClassifier          # √Årbol de decisi√≥n
from sklearn.metrics import accuracy_score, classification_report  # M√©tricas
import pandas as pd                                     # Para mostrar resultados tabulados

# --- 1. Carga del dataset ---
# El dataset Iris contiene 150 muestras con 4 caracter√≠sticas (longitud/peso de p√©talos y s√©palos)
# y 3 clases de flores: setosa, versicolor y virginica.
iris = load_iris()
X = iris.data
y = iris.target

# --- 2. Divisi√≥n del conjunto de datos y escalado ---
# Se divide el dataset en 70% entrenamiento y 30% test.
# Adem√°s, se aplica estandarizaci√≥n para mejorar el rendimiento de SVM y MLP.
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y  # Estratificaci√≥n mantiene proporci√≥n de clases
)

# Escalado de caracter√≠sticas (media 0, desviaci√≥n est√°ndar 1)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# --- 3. Definici√≥n de modelos ---
# Se seleccionan tres modelos para comparar:
# - MLP: red neuronal con 2 capas ocultas de 10 neuronas cada una.
# - SVM: clasificador de vectores de soporte con kernel RBF.
# - √Årbol de decisi√≥n: clasificador basado en divisiones jer√°rquicas.
models = {
    "MLP (Red Neuronal)": MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42),
    "SVM (M√°quina de Vectores de Soporte)": SVC(kernel='rbf', C=1, gamma='scale', random_state=42),
    "√Årbol de Decisi√≥n": DecisionTreeClassifier(random_state=42)
}

# --- 4. Entrenamiento y evaluaci√≥n de los modelos ---
# Se entrena cada modelo y se eval√∫a con exactitud y reporte de clasificaci√≥n.
results = []  # Lista para guardar resultados num√©ricos de cada modelo

for name, model in models.items():
    model.fit(X_train, y_train)                # Entrenamiento
    y_pred = model.predict(X_test)             # Predicciones sobre el test set
    acc = accuracy_score(y_test, y_pred)       # C√°lculo de la exactitud (accuracy)
    
    print("=" * 60)
    print(f"üè∑Ô∏è  Modelo: {name}")
    print(f"üìà Exactitud: {acc:.4f}\n")
    print(classification_report(y_test, y_pred, target_names=iris.target_names))
    
    # Se guarda el resultado para el resumen final
    results.append({"Modelo": name, "Exactitud": acc})

# --- 5. Mostrar resumen ordenado de resultados ---
# Se crea un DataFrame con los resultados y se ordena por exactitud.
print("=" * 60)
print("\nüìä Resumen de exactitudes:\n")
df_results = pd.DataFrame(results).sort_values(by="Exactitud", ascending=False)
print(df_results.to_string(index=False))
